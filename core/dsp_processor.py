"""
Advanced DSP Processor Module - Module x·ª≠ l√Ω DSP ti√™n ti·∫øn
========================================================

Module n√†y ch·ª©a l·ªõp AdvancedDSPProcessor - b·ªô x·ª≠ l√Ω DSP ch√≠nh:
- T√≠ch h·ª£p t·∫•t c·∫£ c√°c module x·ª≠ l√Ω
- Pipeline x·ª≠ l√Ω ho√†n ch·ªânh
- Feature extraction (tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng)
- Video processing (x·ª≠ l√Ω video)

Author: DSP Team
Date: 2025
"""

import numpy as np
import librosa
import soundfile as sf
import subprocess
import os
from .spectral_processing import SpectralProcessor
from .harmonic_enhancement import HarmonicEnhancer
from .noise_gate import NoiseGateProcessor

class AdvancedDSPProcessor:
    """
    B·ªô x·ª≠ l√Ω DSP ti√™n ti·∫øn v·ªõi ƒëi·ªÅu khi·ªÉn tham s·ªë chi ti·∫øt
    Enhanced Digital Signal Processing with detailed parameter control
    
    T√≠ch h·ª£p t·∫•t c·∫£ c√°c module x·ª≠ l√Ω:
    - SpectralProcessor: X·ª≠ l√Ω ph·ªï t√≠n hi·ªáu
    - HarmonicEnhancer: C·∫£i thi·ªán √¢m h√†i
    - NoiseGateProcessor: X·ª≠ l√Ω c·ªïng nhi·ªÖu
    """
    
    def __init__(self, config):
        """
        Kh·ªüi t·∫°o AdvancedDSPProcessor
        Initialize AdvancedDSPProcessor with configuration
        
        Args:
            config: ƒê·ªëi t∆∞·ª£ng c·∫•u h√¨nh DSP
        """
        self.config = config
        self.sr = config.master_config['sample_rate']  # T·∫ßn s·ªë l·∫•y m·∫´u
        self.n_fft = config.stft_config['n_fft']       # K√≠ch th∆∞·ªõc FFT
        self.hop_length = config.stft_config['hop_length']  # Hop length
        
        # Kh·ªüi t·∫°o c√°c module x·ª≠ l√Ω con
        self.spectral_processor = SpectralProcessor(config)
        self.harmonic_enhancer = HarmonicEnhancer(config)
        self.noise_gate_processor = NoiseGateProcessor(config)
        
        # Setup output directory for step-by-step audio exports
        self.output_dir = "./output/dsp_steps"
        os.makedirs(self.output_dir, exist_ok=True)
        self.enable_step_export = True  # Enable/disable step-by-step export
        
        # T√≠nh c√°c tham s·ªë d·∫´n xu·∫•t
        self.frame_duration = self.n_fft / self.sr
        self.hop_duration = self.hop_length / self.sr
        self.overlap_percentage = (self.n_fft - self.hop_length) / self.n_fft * 100
        self.frequency_resolution = self.sr / self.n_fft
        self.time_resolution = self.hop_length / self.sr
        
        print(f"AdvancedDSPProcessor Configuration:")
        print(f"  Sample Rate: {self.sr} Hz")
        print(f"  Frame duration: {self.frame_duration:.1f}ms")
        print(f"  Hop duration: {self.hop_duration:.1f}ms")
        print(f"  Overlap: {self.overlap_percentage:.1f}%")
        print(f"  Frequency resolution: {self.frequency_resolution:.2f}Hz")
        print(f"  Time resolution: {self.time_resolution:.1f}ms")
    
    def _export_step_audio(self, audio, step_name, timestamp=None):
        """
        Export audio from a specific processing step for analysis.
        
        Args:
            audio: Audio data to export
            step_name: Name of the processing step
            timestamp: Optional timestamp for unique filenames
        """
        if not self.enable_step_export:
            return
            
        try:
            import datetime
            
            if timestamp is None:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Clean step name for filename
            clean_step_name = step_name.lower().replace(" ", "_").replace("-", "_")
            filename = f"{timestamp}_{clean_step_name}.wav"
            
            # Use forward slashes for compatibility
            filepath = os.path.join(self.output_dir, filename).replace('\\', '/')
            
            # Ensure output directory exists
            os.makedirs(self.output_dir, exist_ok=True)
            
            # Ensure audio is valid
            if audio is None or len(audio) == 0:
                print(f"    ‚ö†Ô∏è  Warning: Cannot export {step_name} - audio is empty")
                return
                
            # Normalize audio to prevent clipping
            audio_normalized = audio.copy()
            if np.max(np.abs(audio_normalized)) > 0:
                audio_normalized = audio_normalized / np.max(np.abs(audio_normalized)) * 0.95
            
            # Export audio
            sf.write(filepath, audio_normalized, self.sr, subtype='PCM_16')
            print(f"    üìÅ Exported {step_name}: {filename}")
            
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Warning: Failed to export {step_name}: {e}")
    
    def set_step_export(self, enable=True):
        """
        Enable or disable step-by-step audio export.
        
        Args:
            enable: True to enable export, False to disable
        """
        self.enable_step_export = enable
        if enable:
            os.makedirs(self.output_dir, exist_ok=True)
            print(f"‚úì Step-by-step audio export enabled: {self.output_dir}")
        else:
            print("‚úì Step-by-step audio export disabled")
    
    def extract_audio_from_video(self, video_path, output_path="temp_audio.wav"):
        """
        Tr√≠ch xu·∫•t √¢m thanh t·ª´ video s·ª≠ d·ª•ng FFmpeg
        Extract audio from video using FFmpeg
        
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu v√†o
            output_path: ƒê∆∞·ªùng d·∫´n file √¢m thanh ƒë·∫ßu ra
            
        Returns:
            str: ƒê∆∞·ªùng d·∫´n file √¢m thanh ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # L·ªánh FFmpeg ƒë·ªÉ tr√≠ch xu·∫•t √¢m thanh
            cmd = [
                'ffmpeg', '-i', video_path,     # Input video
                '-acodec', 'pcm_s16le',         # Audio codec: 16-bit PCM
                '-ar', str(self.sr),            # Sample rate
                '-ac', '1',                     # Mono channel
                output_path, '-y'               # Output file, overwrite
            ]
            
            # Ch·∫°y l·ªánh v√† b·∫Øt l·ªói
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print(f"‚úì Successfully extracted audio to {output_path}")
            return output_path
            
        except subprocess.CalledProcessError as e:
            print(f"‚úó Error extracting audio: {e}")
            print(f"  stderr: {e.stderr}")
            return None
        except FileNotFoundError:
            print("‚úó Error: FFmpeg not found. Please install FFmpeg.")
            print("  Download from: https://ffmpeg.org/download.html")
            return None
    
    def extract_features(self, audio):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng √¢m thanh to√†n di·ªán
        Extract comprehensive audio features
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh ƒë·∫ßu v√†o
            
        Returns:
            dict: Dictionary ch·ª©a c√°c ƒë·∫∑c tr∆∞ng √¢m thanh
        """
        try:
            features = {}
            
            # MFCCs (Mel-frequency cepstral coefficients)
            features['mfccs'] = librosa.feature.mfcc(y=audio, sr=self.sr, n_mfcc=13)
            
            # ƒê·∫∑c tr∆∞ng ph·ªï - Spectral features
            features['spectral_centroids'] = librosa.feature.spectral_centroid(y=audio, sr=self.sr)
            features['spectral_rolloff'] = librosa.feature.spectral_rolloff(y=audio, sr=self.sr)
            features['spectral_bandwidth'] = librosa.feature.spectral_bandwidth(y=audio, sr=self.sr)
            features['zero_crossing_rate'] = librosa.feature.zero_crossing_rate(audio)
            
            # ƒê·∫∑c tr∆∞ng chroma - Chroma features
            features['chroma'] = librosa.feature.chroma_stft(y=audio, sr=self.sr)
            
            # Tempo v√† nh·ªãp - Tempo and rhythm
            tempo, beats = librosa.beat.beat_track(y=audio, sr=self.sr)
            features['tempo'] = tempo
            features['beats'] = beats
            
            # ƒê·∫∑c tr∆∞ng mel-spectrogram
            features['mel_spectrogram'] = librosa.feature.melspectrogram(y=audio, sr=self.sr)
            
            # K·∫øt h·ª£p c√°c ƒë·∫∑c tr∆∞ng
            combined_features = np.vstack([
                features['mfccs'],
                features['spectral_centroids'],
                features['spectral_rolloff'],
                features['spectral_bandwidth'],
                features['zero_crossing_rate'],
                features['chroma']
            ])
            
            features['combined_features'] = combined_features
            
            return features
            
        except Exception as e:
            print(f"Warning: Feature extraction failed - {e}")
            return None
    
    def process(self, audio):
        """
        Pipeline x·ª≠ l√Ω DSP c·∫£i ti·∫øn ch√≠nh
        Main enhanced DSP processing pipeline
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh ƒë·∫ßu v√†o
            
        Returns:
            dict: K·∫øt qu·∫£ x·ª≠ l√Ω v·ªõi audio ƒë√£ c·∫£i thi·ªán v√† c√°c th√¥ng tin trung gian
        """
        print("Starting enhanced DSP processing...")
        
        # Generate timestamp for this processing session
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # Export original audio
            self._export_step_audio(audio, "00_original_input", timestamp)
            
            # B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω
            print("  1. Preprocessing...")
            preprocessed = self.spectral_processor.preprocess_audio(audio)
            self._export_step_audio(preprocessed, "01_preprocessed", timestamp)
            
            # B∆∞·ªõc 2: Ph√¢n t√≠ch STFT
            print("  2. STFT analysis...")
            stft = librosa.stft(
                preprocessed, 
                n_fft=self.n_fft, 
                hop_length=self.hop_length,
                window=self.config.stft_config['window'],
                center=self.config.stft_config['center'],
                pad_mode=self.config.stft_config['pad_mode']
            )
            
            magnitude = np.abs(stft)
            phase = np.angle(stft)
            
            # B∆∞·ªõc 3: Profiling nhi·ªÖu
            print("  3. Noise profiling...")
            noise_frames = self.config.spectral_subtraction_config['noise_estimation_frames']
            noise_profile = magnitude[:, :min(noise_frames, magnitude.shape[1])]
            noise_psd = np.mean(noise_profile**2, axis=1, keepdims=True)
            
            # B∆∞·ªõc 4: Tr·ª´ ph·ªï c·∫£i ti·∫øn
            print("  4. Enhanced spectral subtraction...")
            enhanced_magnitude = self.spectral_processor.enhanced_spectral_subtraction(
                magnitude, noise_profile
            )
            
            # Export spectral subtraction result
            spectral_subtracted_audio = librosa.istft(
                enhanced_magnitude * np.exp(1j * phase),
                hop_length=self.hop_length,
                window=self.config.stft_config['window']
            )
            self._export_step_audio(spectral_subtracted_audio, "02_spectral_subtracted", timestamp)
            
            # B∆∞·ªõc 5: L·ªçc Wiener
            print("  5. Wiener filtering...")
            wiener_filtered = self.harmonic_enhancer.adaptive_wiener_filter(
                enhanced_magnitude * np.exp(1j * phase), noise_psd
            )
            
            # Export Wiener filtered result
            wiener_filtered_audio = librosa.istft(
                wiener_filtered,
                hop_length=self.hop_length,
                window=self.config.stft_config['window']
            )
            self._export_step_audio(wiener_filtered_audio, "03_wiener_filtered", timestamp)
            
            # B∆∞·ªõc 6: ∆Ø·ªõc t√≠nh t·∫ßn s·ªë c∆° b·∫£n
            print("  6. Fundamental frequency estimation...")
            f0_track = self.spectral_processor.estimate_fundamental_frequency(
                np.abs(wiener_filtered)
            )
            
            # B∆∞·ªõc 7: C·∫£i thi·ªán √¢m h√†i
            print("  7. Harmonic enhancement...")
            harmonic_enhanced = self.harmonic_enhancer.spectral_harmonic_enhancement(
                wiener_filtered, f0_track
            )
            
            # Export harmonic enhanced result
            harmonic_enhanced_audio = librosa.istft(
                harmonic_enhanced,
                hop_length=self.hop_length,
                window=self.config.stft_config['window']
            )
            self._export_step_audio(harmonic_enhanced_audio, "04_harmonic_enhanced", timestamp)
            
            # B∆∞·ªõc 8: T√°i t·∫°o √¢m thanh
            print("  8. Audio reconstruction...")
            enhanced_audio = librosa.istft(
                harmonic_enhanced, 
                hop_length=self.hop_length,
                window=self.config.stft_config['window'],
                center=self.config.stft_config['center']
            )
            
            # B∆∞·ªõc 9: C·ªïng nhi·ªÖu
            print("  9. Noise gating...")
            gated_audio = self.noise_gate_processor.advanced_noise_gate(enhanced_audio)
            self._export_step_audio(gated_audio, "05_noise_gated", timestamp)
            
            # B∆∞·ªõc 10: N√©n d·∫£i ƒë·ªông
            print("  10. Dynamic range compression...")
            compressed_audio = self.noise_gate_processor.dynamic_range_compression(gated_audio)
            self._export_step_audio(compressed_audio, "06_final_compressed", timestamp)
            
            # B∆∞·ªõc 11: Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
            print("  11. Feature extraction...")
            features = self.extract_features(compressed_audio)
            
            # Print export summary
            print(f"\nüìÅ Step-by-step audio files exported to: {self.output_dir}/")
            print(f"   Session timestamp: {timestamp}")
            
            # Tr·∫£ v·ªÅ k·∫øt qu·∫£
            return {
                'enhanced_audio': compressed_audio,
                'enhanced_magnitude': np.abs(harmonic_enhanced),
                'original_phase': phase,
                'fundamental_frequency': f0_track,
                'features': features,
                'intermediate_results': {
                    'preprocessed': preprocessed,
                    'original_magnitude': magnitude,
                    'spectral_subtracted': enhanced_magnitude,
                    'wiener_filtered': np.abs(wiener_filtered),
                    'harmonic_enhanced': np.abs(harmonic_enhanced),
                    'noise_gated': gated_audio,
                    'noise_psd': noise_psd
                }
            }
        
        except Exception as e:
            print(f"‚úó Error in DSP processing: {e}")
            return None
    
    def _calculate_audio_metrics(self, audio):
        """
        T√≠nh to√°n c√°c metrics ch·∫•t l∆∞·ª£ng √¢m thanh
        Calculate audio quality metrics
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh
            
        Returns:
            dict: C√°c metrics ch·∫•t l∆∞·ª£ng
        """
        metrics = {}
        
        # Metrics c∆° b·∫£n
        metrics['rms_energy'] = np.sqrt(np.mean(audio**2))
        metrics['peak_amplitude'] = np.max(np.abs(audio))
        metrics['dynamic_range'] = self._calculate_dynamic_range(audio)
        
        # Metrics ph·ªï
        try:
            metrics['spectral_centroid'] = np.mean(
                librosa.feature.spectral_centroid(y=audio, sr=self.sr)
            )
            metrics['spectral_rolloff'] = np.mean(
                librosa.feature.spectral_rolloff(y=audio, sr=self.sr)
            )
            metrics['zero_crossing_rate'] = np.mean(
                librosa.feature.zero_crossing_rate(audio)
            )
        except Exception as e:
            print(f"Warning: Spectral metrics calculation failed - {e}")
            metrics['spectral_centroid'] = 0
            metrics['spectral_rolloff'] = 0
            metrics['zero_crossing_rate'] = 0
        
        # ∆Ø·ªõc t√≠nh SNR
        metrics['estimated_snr'] = self._estimate_snr(audio)
        
        return metrics
    
    def _calculate_dynamic_range(self, audio):
        """
        T√≠nh d·∫£i ƒë·ªông (dB)
        Calculate dynamic range in dB
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh
            
        Returns:
            float: D·∫£i ƒë·ªông t√≠nh theo dB
        """
        rms = np.sqrt(np.mean(audio**2))
        peak = np.max(np.abs(audio))
        
        if rms > 0:
            return 20 * np.log10(peak / rms)
        else:
            return 0
    
    def _estimate_snr(self, audio):
        """
        ∆Ø·ªõc t√≠nh t·ª∑ l·ªá t√≠n hi·ªáu/nhi·ªÖu
        Estimate Signal-to-Noise Ratio
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh
            
        Returns:
            float: SNR ∆∞·ªõc t√≠nh (dB)
        """
        # ∆Ø·ªõc t√≠nh SNR ƒë∆°n gi·∫£n b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ph·∫ßn y√™n tƒ©nh
        sorted_audio = np.sort(np.abs(audio))
        noise_floor = np.mean(sorted_audio[:int(0.1 * len(sorted_audio))])  # 10% th·∫•p nh·∫•t
        signal_level = np.mean(sorted_audio[int(0.9 * len(sorted_audio)):])  # 10% cao nh·∫•t
        
        if noise_floor > 0:
            return 20 * np.log10(signal_level / noise_floor)
        else:
            return float('inf')
    
    def batch_process(self, input_dir, output_dir, file_pattern="*.wav"):
        """
        X·ª≠ l√Ω h√†ng lo·∫°t file √¢m thanh
        Batch process audio files
        
        Args:
            input_dir: Th∆∞ m·ª•c ƒë·∫ßu v√†o
            output_dir: Th∆∞ m·ª•c ƒë·∫ßu ra
            file_pattern: M·∫´u file (*.wav, *.mp3, etc.)
        """
        import glob
        
        # T·∫°o th∆∞ m·ª•c ƒë·∫ßu ra
        os.makedirs(output_dir, exist_ok=True)
        
        # T√¨m t·∫•t c·∫£ file √¢m thanh
        audio_files = glob.glob(os.path.join(input_dir, file_pattern))
        
        if not audio_files:
            print(f"No audio files found in {input_dir} with pattern {file_pattern}")
            return
        
        print(f"Found {len(audio_files)} audio files to process...")
        
        # X·ª≠ l√Ω t·ª´ng file
        for i, input_path in enumerate(audio_files):
            print(f"\n--- Processing file {i+1}/{len(audio_files)} ---")
            print(f"Input: {os.path.basename(input_path)}")
            
            try:
                # Load audio
                audio, sr = librosa.load(input_path, sr=self.sr)
                
                # Process
                result = self.process(audio)
                
                if result is not None:
                    # Save processed audio
                    output_filename = f"enhanced_{os.path.basename(input_path)}"
                    output_path = os.path.join(output_dir, output_filename)
                    
                    sf.write(output_path, result['enhanced_audio'], sr)
                    print(f"‚úì Successfully processed: {output_filename}")
                else:
                    print(f"‚úó Failed to process: {os.path.basename(input_path)}")
                    
            except Exception as e:
                print(f"‚úó Error processing {os.path.basename(input_path)}: {e}")
        
        print(f"\n--- Batch processing completed ---")
    
    def preprocess_for_ai(self, audio):
        """
        Enhanced pre-processing for AI model input - Full DSP preprocessing pipeline
        Ti·ªÅn x·ª≠ l√Ω n√¢ng cao cho AI model - Pipeline DSP ƒë·∫ßy ƒë·ªß 8 b∆∞·ªõc
        
        Pipeline: Extract Audio ‚Üí Spectral Analysis ‚Üí Noise Reduction ‚Üí Feature Enhancement
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh ƒë·∫ßu v√†o
            
        Returns:
            numpy.ndarray: Audio ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω ƒë·∫ßy ƒë·ªß
        """
        try:
            print("    - Enhanced pre-processing for AI: Full DSP pipeline (8 steps)...")
            
            # Generate timestamp for this preprocessing session
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ========== B∆Ø·ªöC 1: EXTRACT AUDIO (Input) ==========
            print("      Step 1/8: Audio extraction completed")
            self._export_step_audio(audio, "01_ai_preprocessing_input", timestamp)
            
            # ========== B∆Ø·ªöC 2: INITIAL PREPROCESSING ==========
            print("      Step 2/8: Initial preprocessing...")
            preprocessed = self.spectral_processor.preprocess_audio(audio)
            self._export_step_audio(preprocessed, "02_ai_initial_preprocess", timestamp)
            
            # ========== B∆Ø·ªöC 3: SPECTRAL ANALYSIS ==========
            print("      Step 3/8: Spectral analysis...")
            
            # STFT analysis
            stft = librosa.stft(
                preprocessed, 
                n_fft=self.n_fft, 
                hop_length=self.hop_length,
                window=self.config.stft_config['window'],
                center=self.config.stft_config['center'],
                pad_mode=self.config.stft_config['pad_mode']
            )
            
            magnitude = np.abs(stft)
            phase = np.angle(stft)
            print(f"        STFT: {magnitude.shape} frequency bins √ó {magnitude.shape[1]} time frames")
            
            # Noise profiling
            noise_frames = self.config.spectral_subtraction_config['noise_estimation_frames']
            noise_profile = magnitude[:, :min(noise_frames, magnitude.shape[1])]
            noise_psd = np.mean(noise_profile**2, axis=1, keepdims=True)
            print(f"        Noise profiling: {noise_frames} frames analyzed")
            
            # ========== B∆Ø·ªöC 4: ENHANCED SPECTRAL SUBTRACTION ==========
            print("      Step 4/8: Enhanced spectral subtraction...")
            enhanced_magnitude = self.spectral_processor.enhanced_spectral_subtraction(
                magnitude, noise_profile
            )
            
            # Export spectral subtraction result
            spectral_subtracted_stft = enhanced_magnitude * np.exp(1j * phase)
            spectral_subtracted_audio = librosa.istft(
                spectral_subtracted_stft,
                hop_length=self.hop_length,
                window=self.config.stft_config['window']
            )
            self._export_step_audio(spectral_subtracted_audio, "03_ai_spectral_subtracted", timestamp)
            
            # ========== B∆Ø·ªöC 5: WIENER FILTERING ==========
            print("      Step 5/8: Wiener filtering...")
            wiener_filtered = self.harmonic_enhancer.adaptive_wiener_filter(
                spectral_subtracted_stft, noise_psd
            )
            
            # Export Wiener filtered result
            wiener_filtered_audio = librosa.istft(
                wiener_filtered,
                hop_length=self.hop_length,
                window=self.config.stft_config['window']
            )
            self._export_step_audio(wiener_filtered_audio, "04_ai_wiener_filtered", timestamp)
            
            # ========== B∆Ø·ªöC 6: HARMONIC ENHANCEMENT ==========
            print("      Step 6/8: Feature enhancement - Harmonic enhancement...")
            
            # F0 estimation for harmonic enhancement
            f0_track = self.spectral_processor.estimate_fundamental_frequency(
                np.abs(wiener_filtered)
            )
            print(f"        F0 tracking: {len(f0_track)} frames estimated")
            
            # Harmonic enhancement
            harmonic_enhanced = self.harmonic_enhancer.spectral_harmonic_enhancement(
                wiener_filtered, f0_track
            )
            
            # Audio reconstruction with enhanced features
            enhanced_audio = librosa.istft(
                harmonic_enhanced, 
                hop_length=self.hop_length,
                window=self.config.stft_config['window'],
                center=self.config.stft_config['center']
            )
            self._export_step_audio(enhanced_audio, "05_ai_harmonic_enhanced", timestamp)
            
            # ========== B∆Ø·ªöC 7: NOISE GATING ==========
            print("      Step 7/8: Noise gating...")
            gated_audio = self.noise_gate_processor.advanced_noise_gate(enhanced_audio)
            self._export_step_audio(gated_audio, "06_ai_noise_gated", timestamp)
            
            # ========== B∆Ø·ªöC 8: DYNAMIC COMPRESSION ==========
            print("      Step 8/8: Dynamic range compression...")
            compressed_audio = self.noise_gate_processor.dynamic_range_compression(gated_audio)
            self._export_step_audio(compressed_audio, "07_ai_compressed", timestamp)
            
            # ========== FINAL NORMALIZATION ==========
            print("      Final: Normalization for AI input...")
            
            # Final normalization optimized for AI model input
            final_audio = librosa.util.normalize(compressed_audio)
            
            # Export final preprocessed audio
            self._export_step_audio(final_audio, "08_preprocessed_for_ai", timestamp)
            
            # Print comprehensive preprocessing summary
            print(f"    ‚úì Enhanced pre-processing completed - Full 8-step DSP pipeline")
            print(f"      Input length: {len(audio)} samples ({len(audio)/self.sr:.2f}s)")
            print(f"      Output length: {len(final_audio)} samples ({len(final_audio)/self.sr:.2f}s)")
            
            # Print export summary
            print(f"\n    üìÅ Pre-processing exports (Session: {timestamp}):")
            print(f"      01_ai_preprocessing_input.wav     - Original input")
            print(f"      02_ai_initial_preprocess.wav      - Initial preprocessing")  
            print(f"      03_ai_spectral_subtracted.wav     - After spectral subtraction")
            print(f"      04_ai_wiener_filtered.wav         - After Wiener filtering")
            print(f"      05_ai_harmonic_enhanced.wav       - After harmonic enhancement")
            print(f"      06_ai_noise_gated.wav             - After noise gating")
            print(f"      07_ai_compressed.wav              - After compression")
            print(f"      08_preprocessed_for_ai.wav        - Final preprocessed for AI")
            print(f"    üìä Total: 8 audio files exported to: {self.output_dir}/")
            
            return final_audio
            
        except Exception as e:
            print(f"    ‚úó Enhanced pre-processing failed: {e}")
            print(f"      Error details: {str(e)}")
            print("    ‚Üí Falling back to simple preprocessing...")
            
            # Fallback to simple preprocessing
            try:
                normalized_audio = librosa.util.normalize(audio)
                # Export fallback result
                import datetime
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                self._export_step_audio(normalized_audio, "fallback_preprocessed_for_ai", timestamp)
                return normalized_audio
            except:
                print("    ‚Üí Using original audio as last resort...")
                return audio

    def process_audio(self, audio):
        """
        Simple audio processing method that returns only the enhanced audio.
        Method x·ª≠ l√Ω √¢m thanh ƒë∆°n gi·∫£n ch·ªâ tr·∫£ v·ªÅ audio ƒë√£ c·∫£i thi·ªán.
        
        Args:
            audio: T√≠n hi·ªáu √¢m thanh ƒë·∫ßu v√†o
            
        Returns:
            numpy.ndarray: Audio ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        try:
            # Use the main process method
            result = self.process(audio)
            
            if result is None or 'enhanced_audio' not in result:
                print("    ‚úó DSP processing failed, returning original audio")
                return audio
            
            return result['enhanced_audio']
            
        except Exception as e:
            print(f"    ‚úó Audio processing error: {e}")
            return audio

if __name__ == "__main__":
    # Test code
    from config.dsp_config import DSPConfiguration
    
    config = DSPConfiguration()
    processor = AdvancedDSPProcessor(config)
    
    # T·∫°o t√≠n hi·ªáu test
    test_audio = np.random.randn(22050)  # 1 gi√¢y √¢m thanh
    
    # X·ª≠ l√Ω
    result = processor.process(test_audio)
    
    if result is not None:
        print(f"‚úì Processing successful!")
        print(f"  Original length: {len(test_audio)} samples")
        print(f"  Enhanced length: {len(result['enhanced_audio'])} samples")
        print(f"  Features extracted: {result['features'] is not None}")
    else:
        print("‚úó Processing failed!")
    
    print("AdvancedDSPProcessor test completed!")
